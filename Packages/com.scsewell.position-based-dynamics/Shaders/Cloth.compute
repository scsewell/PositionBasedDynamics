#include "HLSLSupport.cginc"
#include "ClothCore.hlsl"

//#pragma use_dxc
//#pragma enable_d3d11_debug_symbols

#pragma kernel CSMain

// TODO: decrease size? would need to use global memory to share results,
// or ensure groups are entirely separate chunks of verts/tris (how to handle overlap?)
#define THREAD_GROUP_SIZE       1024
#define SHARED_MEMORY_SIZE      ((32 * 1024) / 4)
#define MAX_SHARED_POSITIONS    (SHARED_MEMORY_SIZE / 3)
#define CURR_POSITIONS_OFFSET   0
#define PREV_POSITIONS_OFFSET   (MAX_SHARED_POSITIONS / 2)

groupshared uint gs_Data[SHARED_MEMORY_SIZE];

void StorePosition(uint index, float3 position)
{
    gs_Data[(3 * index) + 0] = asuint(position.x);
    gs_Data[(3 * index) + 1] = asuint(position.y);
    gs_Data[(3 * index) + 2] = asuint(position.z);
}

float3 LoadPosition(uint index)
{
    uint3 position;
    position.x = gs_Data[(3 * index) + 0];
    position.y = gs_Data[(3 * index) + 1];
    position.z = gs_Data[(3 * index) + 2];
    return asfloat(position);
}

void StoreCurrPosition(uint index, float3 position)
{
    StorePosition(CURR_POSITIONS_OFFSET + index, position);
}

void StorePrevPosition(uint index, float3 position)
{
    StorePosition(PREV_POSITIONS_OFFSET + index, position);
}

float3 LoadCurrPosition(uint index)
{
    return LoadPosition(CURR_POSITIONS_OFFSET + index);
}

float3 LoadPrevPosition(uint index)
{
    return LoadPosition(PREV_POSITIONS_OFFSET + index);
}

/*
Particle LoadParticleGlobal(uint index)
{
    bool isValid = index < _ParticleCount;
    
    Particle particle;
    particle.inverseMass = isValid ? _InverseMasses[index] : 0;
    particle.currentPosition = isValid ? _CurrentPositions[index].xyz : 0;
    particle.previousPosition = isValid ? _PreviousPositions[index].xyz : 0;
    return particle;
}

void StoreParticleGlobal(uint index, Particle particle)
{
    if (index < _ParticleCount)
    {
        _CurrentPositions[index].xyz = particle.currentPosition;
        _PreviousPositions[index].xyz = particle.previousPosition;
    }
}

Particle LoadParticleLocal(uint index)
{
    bool isValid = index < _ParticleCount;

    float3 data0 = isValid ? gs_Data[index] : 0;
    float3 data1 = isValid ? gs_Data[(SHARED_MEMORY_SIZE / 24) + index] : 0;

    Particle particle;
    particle.inverseMass = asuint(data0.x) & 0x1;
    particle.currentPosition = data0;
    particle.previousPosition = data1;
    return particle;
}

void StoreParticleLocal(uint index, Particle particle)
{
    float3 data0 = particle.currentPosition;
    float3 data1 = particle.previousPosition;
    data0.x = asfloat((asuint(data0.x)& ~0x1) | uint(particle.inverseMass));
    
    if (index < _ParticleCount)
    {
        gs_Data[index] = data0;
        gs_Data[(SHARED_MEMORY_SIZE / 24) + index] = data1;
    }
}
*/

void Integrate(inout float3 currentPosition, inout float3 previousPosition, float inverseMass)
{
    float3 posDeltaFromVelocity = currentPosition - previousPosition;
    float3 posDeltaFromAccelration = _Gravity * _SubStepDeltaTime * _SubStepDeltaTime;
    float3 posDelta = posDeltaFromVelocity + posDeltaFromAccelration;
    
    previousPosition = currentPosition;
    currentPosition += inverseMass * posDelta;
}

void SolveDistanceConstraints(uint threadID, uint localID, uint groupID)
{
    // Process constraints in batches where no two constraints in the same batch
    // affect the same particles. This avoids the need to write atomically.

    // todo: profile unroll, see if registr increase is a real problem
    [unroll(MAX_CONSTRAINT_BATCHES)]
    for (uint batch = 0; batch < _ConstraintBatchCount; batch++)
    {
        uint3 batchData = _ConstraintBatchData[batch].xyz;
        uint batchOffset = batchData.x;
        uint batchSize = batchData.y;
        float compliance = asfloat(batchData.z);
        
        DistanceConstraint constraint = LoadDistanceConstraint(threadID, batchOffset);

        float w0 = _InverseMasses[constraint.indices.x];
        float w1 = _InverseMasses[constraint.indices.y];
        float3 p0 = LoadCurrPosition(constraint.indices.x);
        float3 p1 = LoadCurrPosition(constraint.indices.y);

        float3 disp = p0 - p1;
        float len = length(disp);
        float3 dir = len != 0 ? disp / len : 0;
        
        float c = len - constraint.restLength;
        float alpha = compliance / (_SubStepDeltaTime * _SubStepDeltaTime);
        float w = w0 + w1;
        float s = -c / (w + alpha);
        
        p0 += dir * (s * w0);
        p1 -= dir * (s * w1);
        
        if (threadID < batchSize)
        {
            StoreCurrPosition(constraint.indices.x, p0);
            StoreCurrPosition(constraint.indices.y, p1);
        }
        
        GroupMemoryBarrierWithGroupSync();
    }
}

void SumTriangleNormals(uint triangleIndex)
{
    // TODO: consider groupshared memory for normals?
    // TODO: compress normals
    uint3 tri = LoadTriangle(triangleIndex);

    float3 p0 = LoadCurrPosition(tri.x);
    float3 p1 = LoadCurrPosition(tri.y);
    float3 p2 = LoadCurrPosition(tri.z);

    float3 normal = normalize(cross(p1 - p0, p2 - p0));
    
    uint seed = tri.x + tri.y + tri.z;

    if (triangleIndex < _TriangleCount)
    {
        AtomicAdd(_Normals, tri.x, normal, seed);
        AtomicAdd(_Normals, tri.y, normal, seed);
        AtomicAdd(_Normals, tri.z, normal, seed);
    }
}

void SumTriangleNormals(uint threadID, uint localID, uint groupID)
{
    // TODO: graph coloring to avoid atomics?
    UNITY_UNROLL
    for (uint p = 0; p < PARTICLES_PER_THREAD; p++)
    {
        uint index = (2 * threadID) + p;
        
        _Normals[index] = asuint(float4(0, 0, 0, 0));
    }
    
    DeviceMemoryBarrierWithGroupSync(); 

    uint totalThreads = THREAD_GROUP_SIZE * _ThreadGroupCount;

    //uint trianglesPerThread = _TriangleCount / (THREAD_GROUP_SIZE * _ThreadGroupCount);
    uint trianglesPerThread = ((_TriangleCount - 1) / totalThreads) + 1;
    
    for (uint i = 0; i < trianglesPerThread; i++)
    {
        uint index = (trianglesPerThread * ((THREAD_GROUP_SIZE * groupID) + threadID)) + i;
        SumTriangleNormals(index);
    }
    
    DeviceMemoryBarrierWithGroupSync(); 
}

void StoreMeshVertex(uint index, float3 position, float3 normal)
{
    uint byteAddress = 3 * 4 * index;
    _MeshPositions.Store3(byteAddress, asuint(position));
    _MeshNormals.Store3(byteAddress, asuint(normal));
}

[numthreads(THREAD_GROUP_SIZE, 1, 1)]
void CSMain(uint threadID : SV_DispatchThreadID, uint localID : SV_GroupThreadID, uint groupID : SV_GroupID)
{
    UNITY_UNROLL
    for (uint p = 0; p < PARTICLES_PER_THREAD; p++)
    {
        uint index = (2 * threadID) + p;
        
        StoreCurrPosition(index, _CurrentPositions[index].xyz);
        StorePrevPosition(index, _PreviousPositions[index].xyz);
    }

    for (uint i = 0; i < _SubStepCount; i++)
    {
        UNITY_UNROLL
        for (uint p = 0; p < PARTICLES_PER_THREAD; p++)
        {
            uint index = (2 * threadID) + p;

            float inverseMass = _InverseMasses[index];
            float3 currPos = LoadCurrPosition(index);
            float3 prevPos = LoadPrevPosition(index);
        
            Integrate(currPos, prevPos, inverseMass);
            
            StoreCurrPosition(index, currPos);
            StorePrevPosition(index, prevPos);
        }

        // TODO: may need to write more positions per thread if there are more positions allowed
        // I suppose we can write the positions to global memory, then each group loads all into LDS
        GroupMemoryBarrierWithGroupSync();

        SolveDistanceConstraints(threadID, localID, groupID);
    }
    
    SumTriangleNormals(threadID, localID, groupID);
    
    UNITY_UNROLL
    for (uint p = 0; p < PARTICLES_PER_THREAD; p++)
    {
        uint index = (2 * threadID) + p;

        float3 currPos = LoadCurrPosition(index);
        float3 prevPos = LoadPrevPosition(index);

        float3 normalSum = asfloat(_Normals[index]);
        float3 normal = normalize(normalSum);
        
        if (threadID < _ParticleCount)
        {
            _CurrentPositions[index].xyz = currPos;
            _PreviousPositions[index].xyz = prevPos;

            StoreMeshVertex(index, currPos, normal);
        }
    }
}
